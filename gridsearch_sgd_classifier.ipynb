{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from pandas_ml import ConfusionMatrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters used for gridsearch\n",
    "Both pipline for the pre-process data and the original data are search for the best parameters from this parameters list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.25,0.5, 0.75),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (1e-06,1e-05,1e-04,1e-03,1e-02),\n",
    "    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "    'clf__loss' : ('hinge', 'log'),\n",
    "    'clf__l1_ratio':(0.1,0.15,0.2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the pre-processing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/drop_dup.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.new_phrase\n",
    "y = data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(token_pattern=r'(?u)[\\wA-Za-z][\\wA-Za-z]+')),\n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', SGDClassifier(random_state=42, verbose=1, loss = 'log',l1_ratio=0.15,max_iter = 10)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 57.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 70.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 82.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed: 86.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 77.24, NNZs: 15876, Bias: -1.870356, T: 76512, Avg. loss: 0.135034\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 64.56, NNZs: 14561, Bias: -1.581750, T: 153024, Avg. loss: 0.082272\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59.44, NNZs: 14493, Bias: -1.408847, T: 229536, Avg. loss: 0.074071\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56.54, NNZs: 14657, Bias: -1.390110, T: 306048, Avg. loss: 0.070316\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 54.68, NNZs: 14734, Bias: -1.372738, T: 382560, Avg. loss: 0.068083\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53.56, NNZs: 14836, Bias: -1.336795, T: 459072, Avg. loss: 0.066614\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.73, NNZs: 14901, Bias: -1.299349, T: 535584, Avg. loss: 0.065655\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.04, NNZs: 15069, Bias: -1.283320, T: 612096, Avg. loss: 0.064779\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 51.52, NNZs: 15156, Bias: -1.291081, T: 688608, Avg. loss: 0.064237\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 51.21, NNZs: 15145, Bias: -1.276940, T: 765120, Avg. loss: 0.063630\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 155.01, NNZs: 40939, Bias: -1.323895, T: 76512, Avg. loss: 0.501880\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 134.08, NNZs: 39177, Bias: -1.171947, T: 153024, Avg. loss: 0.297816\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 126.78, NNZs: 38036, Bias: -1.094029, T: 229536, Avg. loss: 0.262125\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 122.95, NNZs: 37713, Bias: -1.079318, T: 306048, Avg. loss: 0.245712\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 120.62, NNZs: 37394, Bias: -1.026452, T: 382560, Avg. loss: 0.236656\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 119.00, NNZs: 37435, Bias: -1.038544, T: 459072, Avg. loss: 0.230640\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 117.84, NNZs: 37449, Bias: -1.016975, T: 535584, Avg. loss: 0.226334\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 117.02, NNZs: 37412, Bias: -1.022962, T: 612096, Avg. loss: 0.223591\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 116.31, NNZs: 37448, Bias: -1.013056, T: 688608, Avg. loss: 0.221335\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 115.80, NNZs: 37620, Bias: -1.005016, T: 765120, Avg. loss: 0.219456\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 222.71, NNZs: 58888, Bias: 0.999063, T: 76512, Avg. loss: 0.902996\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 197.02, NNZs: 56663, Bias: 1.015079, T: 153024, Avg. loss: 0.507456\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 188.83, NNZs: 56566, Bias: 0.998831, T: 229536, Avg. loss: 0.442638\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 185.36, NNZs: 56994, Bias: 1.005248, T: 306048, Avg. loss: 0.412467\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 183.14, NNZs: 57330, Bias: 0.986291, T: 382560, Avg. loss: 0.394227\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.60, NNZs: 57490, Bias: 1.014117, T: 459072, Avg. loss: 0.382174\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 180.41, NNZs: 57732, Bias: 0.998772, T: 535584, Avg. loss: 0.373686\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 179.80, NNZs: 57938, Bias: 1.006455, T: 612096, Avg. loss: 0.367349\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 179.12, NNZs: 58133, Bias: 1.008390, T: 688608, Avg. loss: 0.362654\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 178.69, NNZs: 58347, Bias: 1.009875, T: 765120, Avg. loss: 0.358538\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 167.22, NNZs: 45903, Bias: -1.522032, T: 76512, Avg. loss: 0.600755\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 144.80, NNZs: 44213, Bias: -1.116690, T: 153024, Avg. loss: 0.356697\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 137.13, NNZs: 43631, Bias: -1.116776, T: 229536, Avg. loss: 0.314068\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 133.27, NNZs: 43395, Bias: -1.099826, T: 306048, Avg. loss: 0.295148\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 131.15, NNZs: 43536, Bias: -1.054103, T: 382560, Avg. loss: 0.284016\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 129.61, NNZs: 43647, Bias: -1.032216, T: 459072, Avg. loss: 0.276708\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 128.51, NNZs: 43804, Bias: -1.026869, T: 535584, Avg. loss: 0.271175\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 127.80, NNZs: 44021, Bias: -1.012634, T: 612096, Avg. loss: 0.267528\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 127.22, NNZs: 44262, Bias: -1.015792, T: 688608, Avg. loss: 0.264422\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 126.75, NNZs: 44467, Bias: -1.028582, T: 765120, Avg. loss: 0.262262\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 91.35, NNZs: 19676, Bias: -1.845416, T: 76512, Avg. loss: 0.173675\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 77.16, NNZs: 18722, Bias: -1.657742, T: 153024, Avg. loss: 0.105544\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71.73, NNZs: 18610, Bias: -1.595552, T: 229536, Avg. loss: 0.094273\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 68.83, NNZs: 18574, Bias: -1.497278, T: 306048, Avg. loss: 0.089344\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 67.11, NNZs: 18846, Bias: -1.438726, T: 382560, Avg. loss: 0.086234\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.92, NNZs: 18883, Bias: -1.420069, T: 459072, Avg. loss: 0.084376\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 65.10, NNZs: 19066, Bias: -1.399600, T: 535584, Avg. loss: 0.082729\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 64.51, NNZs: 19219, Bias: -1.421302, T: 612096, Avg. loss: 0.081740\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 64.10, NNZs: 19307, Bias: -1.357677, T: 688608, Avg. loss: 0.080662\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 63.70, NNZs: 19440, Bias: -1.370439, T: 765120, Avg. loss: 0.080002\n",
      "Total training time: 0.21 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__alpha': (1e-06, 1e-05, 0.0001, 0.001, 0.01),\n",
       "                         'clf__l1_ratio': (0.1, 0.15, 0.2),\n",
       "                         'clf__loss': ('hinge', 'log'),\n",
       "                         'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
       "                         'tfidf__norm': ('l1', 'l2'),\n",
       "                         'vect__max_df': (0.25, 0.5, 0.75),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.620\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__l1_ratio: 0.1\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__norm: 'l2'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = grid_search.best_estimator_\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6259605834073919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.48      0.25      0.32       806\n",
      " somehow pos       0.51      0.35      0.41      3209\n",
      "     neutral       0.68      0.86      0.76     10087\n",
      " somehow neg       0.55      0.42      0.48      3952\n",
      "         neg       0.50      0.30      0.38      1075\n",
      "\n",
      "    accuracy                           0.63     19129\n",
      "   macro avg       0.54      0.44      0.47     19129\n",
      "weighted avg       0.60      0.63      0.60     19129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy = \"+ str(np.mean(y_pred == y_test)))\n",
    "my_tags = ['neg','somehow neg','neutral','somehow pos','pos']\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred,\n",
    "    target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = data.Phrase\n",
    "y2 = data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer(token_pattern=r'(?u)[\\wA-Za-z][\\wA-Za-z]+')), \n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(random_state=42, verbose=1, loss = 'log',l1_ratio=0.15,max_iter = 10)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline2 is search for the best parameters with parameters set provide at the start of the code\n",
    "grid_search2 = GridSearchCV(pipeline2, parameters, cv=5,n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 65.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 80.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 96.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 115.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed: 123.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 301.36, NNZs: 93706, Bias: -6.003200, T: 124848, Avg. loss: 0.248928\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 245.25, NNZs: 93706, Bias: -5.908272, T: 249696, Avg. loss: 0.109648\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 229.21, NNZs: 93706, Bias: -5.574096, T: 374544, Avg. loss: 0.087679\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 222.81, NNZs: 93706, Bias: -5.479595, T: 499392, Avg. loss: 0.079450\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 218.92, NNZs: 93706, Bias: -5.578784, T: 624240, Avg. loss: 0.075548\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 216.73, NNZs: 93706, Bias: -5.464679, T: 749088, Avg. loss: 0.073026\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 215.52, NNZs: 93706, Bias: -5.328200, T: 873936, Avg. loss: 0.071367\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 213.96, NNZs: 93706, Bias: -5.473246, T: 998784, Avg. loss: 0.070153\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 213.21, NNZs: 93706, Bias: -5.427945, T: 1123632, Avg. loss: 0.069363\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 212.35, NNZs: 93706, Bias: -5.463933, T: 1248480, Avg. loss: 0.068593\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 545.75, NNZs: 93706, Bias: -3.755358, T: 124848, Avg. loss: 0.836889\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 418.40, NNZs: 93706, Bias: -3.161201, T: 249696, Avg. loss: 0.345729\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 378.02, NNZs: 93706, Bias: -3.180110, T: 374544, Avg. loss: 0.270533\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 359.76, NNZs: 93706, Bias: -3.160935, T: 499392, Avg. loss: 0.246546\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 350.28, NNZs: 93706, Bias: -2.958489, T: 624240, Avg. loss: 0.234253\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 343.95, NNZs: 93706, Bias: -3.130837, T: 749088, Avg. loss: 0.227123\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 340.03, NNZs: 93706, Bias: -3.033483, T: 873936, Avg. loss: 0.222338\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 336.86, NNZs: 93706, Bias: -3.069434, T: 998784, Avg. loss: 0.218963\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 334.38, NNZs: 93706, Bias: -3.092393, T: 1123632, Avg. loss: 0.216320\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 332.72, NNZs: 93706, Bias: -3.015142, T: 1248480, Avg. loss: 0.214310\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 698.55, NNZs: 93706, Bias: 2.947030, T: 124848, Avg. loss: 1.344865\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 520.18, NNZs: 93706, Bias: 2.648440, T: 249696, Avg. loss: 0.528225\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 463.14, NNZs: 93706, Bias: 2.393994, T: 374544, Avg. loss: 0.410208\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 437.67, NNZs: 93706, Bias: 2.142623, T: 499392, Avg. loss: 0.373804\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 423.64, NNZs: 93706, Bias: 2.180492, T: 624240, Avg. loss: 0.357091\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 414.78, NNZs: 93706, Bias: 2.324122, T: 749088, Avg. loss: 0.346419\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 408.77, NNZs: 93706, Bias: 2.225005, T: 873936, Avg. loss: 0.339504\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 404.36, NNZs: 93706, Bias: 2.136404, T: 998784, Avg. loss: 0.334613\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 400.93, NNZs: 93706, Bias: 2.149827, T: 1123632, Avg. loss: 0.330814\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 398.34, NNZs: 93706, Bias: 2.102759, T: 1248480, Avg. loss: 0.327893\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 576.10, NNZs: 93706, Bias: -3.352930, T: 124848, Avg. loss: 0.979674\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 439.82, NNZs: 93706, Bias: -3.051697, T: 249696, Avg. loss: 0.404224\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 395.85, NNZs: 93706, Bias: -2.778379, T: 374544, Avg. loss: 0.315962\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 376.49, NNZs: 93706, Bias: -2.794511, T: 499392, Avg. loss: 0.287172\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 366.02, NNZs: 93706, Bias: -2.747959, T: 624240, Avg. loss: 0.273107\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 359.03, NNZs: 93706, Bias: -2.834923, T: 749088, Avg. loss: 0.264584\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 354.47, NNZs: 93706, Bias: -2.763058, T: 873936, Avg. loss: 0.258828\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 351.06, NNZs: 93706, Bias: -2.775211, T: 998784, Avg. loss: 0.254975\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 348.51, NNZs: 93706, Bias: -2.733300, T: 1123632, Avg. loss: 0.251911\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 346.42, NNZs: 93706, Bias: -2.762823, T: 1248480, Avg. loss: 0.249610\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 332.70, NNZs: 93706, Bias: -6.775738, T: 124848, Avg. loss: 0.295429\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 265.81, NNZs: 93706, Bias: -5.894301, T: 249696, Avg. loss: 0.128468\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 246.23, NNZs: 93706, Bias: -5.628678, T: 374544, Avg. loss: 0.101692\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 238.49, NNZs: 93706, Bias: -5.421528, T: 499392, Avg. loss: 0.092996\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 233.79, NNZs: 93706, Bias: -5.376979, T: 624240, Avg. loss: 0.088087\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 230.96, NNZs: 93706, Bias: -5.456556, T: 749088, Avg. loss: 0.085297\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 228.79, NNZs: 93706, Bias: -5.579404, T: 873936, Avg. loss: 0.083499\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 227.44, NNZs: 93706, Bias: -5.464717, T: 998784, Avg. loss: 0.082184\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 226.41, NNZs: 93706, Bias: -5.494671, T: 1123632, Avg. loss: 0.081172\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 225.80, NNZs: 93706, Bias: -5.374362, T: 1248480, Avg. loss: 0.080388\n",
      "Total training time: 0.35 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__alpha': (1e-06, 1e-05, 0.0001, 0.001, 0.01),\n",
       "                         'clf__l1_ratio': (0.1, 0.15, 0.2),\n",
       "                         'clf__loss': ('hinge', 'log'),\n",
       "                         'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
       "                         'tfidf__norm': ('l1', 'l2'),\n",
       "                         'vect__max_df': (0.25, 0.5, 0.75),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-06\n",
      "\tclf__l1_ratio: 0.1\n",
      "\tclf__loss: 'log'\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__norm: 'l2'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters2 = grid_search2.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2 = grid_search2.best_estimator_\n",
    "y_pred2 = grid_search2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6554850698449315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.51      0.38      0.44      1428\n",
      " somehow pos       0.55      0.48      0.51      5435\n",
      "     neutral       0.72      0.82      0.77     15989\n",
      " somehow neg       0.58      0.53      0.55      6523\n",
      "         neg       0.55      0.43      0.48      1837\n",
      "\n",
      "    accuracy                           0.66     31212\n",
      "   macro avg       0.58      0.53      0.55     31212\n",
      "weighted avg       0.64      0.66      0.65     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy = \"+ str(np.mean(y_pred2 == y_test2)))\n",
    "my_tags = ['neg','somehow neg','neutral','somehow pos','pos']\n",
    "\n",
    "print(metrics.classification_report(y_test2, y_pred2,\n",
    "    target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_search, 'grid_sgd_dup.pkl')\n",
    "joblib.dump(grid_search2, 'grid_sgd_ori.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
