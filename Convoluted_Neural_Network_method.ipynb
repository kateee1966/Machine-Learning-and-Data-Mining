{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Embedding, Flatten\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.tsv'',  sep=\"\\t\")\n",
    "test = pd.read_csv('dataset/test.tsv',  sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sentiment'].value_counts()\n",
    "# 0 - negative\n",
    "# 1 - somewhat negative\n",
    "# 2 - neutral\n",
    "# 3 - somewhat positive\n",
    "# 4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format data to process by CNN\n",
    "def format_data(train, test, max_features, maxlen):\n",
    "\n",
    "    # shuffle training data\n",
    "    train = train.sample(frac=1).reset_index(drop = True)\n",
    "    \n",
    "    # convert all phrases to lower case\n",
    "    train['Phrase'] = train['Phrase'].apply(lambda x: x.lower())\n",
    "    test['Phrase'] = test['Phrase'].apply(lambda x: x.lower())\n",
    "   \n",
    "    # training phrases - features\n",
    "    X = train['Phrase']\n",
    "    # test phrases - features\n",
    "    test_X = test['Phrase']\n",
    "    # sentiment values - labels (as categorical)\n",
    "    Y = to_categorical(train['Sentiment'].values)\n",
    "    \n",
    "    # keras tokenizer, max num_words = max_features\n",
    "    tokenizer = Tokenizer(num_words = max_features)\n",
    "    # fit to training phrases\n",
    "    tokenizer.fit_on_texts(list(X))\n",
    "    \n",
    "    # convert training text to sequence\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    # convert training sequence to 2D array, each element contains sequence of length 'maxlen'\n",
    "    X = pad_sequences(X, maxlen = maxlen)\n",
    "    # convert test text...\n",
    "    test_X = tokenizer.texts_to_sequences(test_X)\n",
    "    # convert test sequence to 2D array...\n",
    "    test_X = pad_sequences(test_X, maxlen = maxlen)\n",
    "    \n",
    "    return X, Y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 125\n",
    "max_features = 10000\n",
    "\n",
    "X, Y, test_X = format_data(train, test, max_features, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  165,   69,   59],\n",
       "       [   0,    0,    0, ...,    0,  186,  500],\n",
       "       [   0,    0,    0, ..., 6908,    4, 1383],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0, 5018],\n",
       "       [   0,    0,    0, ...,    6, 8428,  390],\n",
       "       [   0,    0,    0, ...,    0, 2612, 7696]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  613, 1029,  392],\n",
       "       [   0,    0,    0, ...,  613, 1029,  392],\n",
       "       [   0,    0,    0, ...,    0,    0,   16],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    2,  126, 5773],\n",
       "       [   0,    0,    0, ...,    2,  126, 5773],\n",
       "       [   0,    0,    0, ...,    0,  373, 2013]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X # test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training (75%) and testing sets (25%)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# building CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# add embedding layer for the input sequence\n",
    "# see: https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12\n",
    "model.add(Embedding(max_features, 150, input_length=maxlen))\n",
    "\n",
    "# use SpatialDropout to avoid overfitting\n",
    "# see: https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/76883\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# CNN\n",
    "# layer 1\n",
    "model.add(Conv1D(32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# layer 2\n",
    "model.add(Conv1D(64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# flatten pooling layer\n",
    "# see: https://missinglink.ai/guides/deep-learning-frameworks/using-keras-flatten-operation-cnn-models-code-examples/\n",
    "model.add(Flatten())\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(5, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify epoch and batch size\n",
    "epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 117045 samples, validate on 39015 samples\n",
      "Epoch 1/5\n",
      "117045/117045 [==============================] - 43s 370us/step - loss: 1.0178 - acc: 0.5882 - val_loss: 0.8807 - val_acc: 0.6386\n",
      "Epoch 2/5\n",
      "117045/117045 [==============================] - 38s 323us/step - loss: 0.8169 - acc: 0.6575 - val_loss: 0.8395 - val_acc: 0.6549\n",
      "Epoch 3/5\n",
      "117045/117045 [==============================] - 43s 369us/step - loss: 0.7462 - acc: 0.6851 - val_loss: 0.8521 - val_acc: 0.6505\n",
      "Epoch 4/5\n",
      "117045/117045 [==============================] - 44s 374us/step - loss: 0.6967 - acc: 0.7053 - val_loss: 0.8432 - val_acc: 0.6639\n",
      "Epoch 5/5\n",
      "117045/117045 [==============================] - 46s 394us/step - loss: 0.6565 - acc: 0.7218 - val_loss: 0.8949 - val_acc: 0.6610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14fa3b70>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification - use categorical cross entropy as loss function\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# fit the model and train\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs = epochs, batch_size = batch_size, verbose = 1)\n",
    "\n",
    "# around 0.70 accuracy after 5 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
